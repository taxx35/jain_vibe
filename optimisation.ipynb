{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e74fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /usr/local/bin/python3.12 -m pip install \"tensorflow==2.20.*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff602187",
   "metadata": {},
   "source": [
    "# Full optimisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bbe180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading final_all_descriptors.csv ...\n",
      "Training Elastic-Net VIBE classifier on 5 features ...\n",
      "VIBE gate: ROC-AUC=0.678 | AP=0.345 | thr=0.456\n",
      "Generating single mutants in CDR3 (heavy & light) ...\n",
      "Mutants generated: 1595 over 147 parents\n",
      "Preparing DeepSP input and invoking deepsp_predictor.py ...\n",
      "DeepSP will run with: /Users/tahuraazazattar/miniconda3/envs/deepsp_env/bin/python\n",
      "\n",
      "Optimization complete.\n",
      "Low-VIBE survivors ranked by HydroScore38 → opt_outputs_desc/optimized_mutants_descriptor_only.csv\n",
      "Gate: thr=0.456 (recall floor 0.60)  |  survivors: 222 / 1595\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os, sys, warnings, subprocess\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, average_precision_score\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "RANDOM_STATE     = 42\n",
    "VIBE_HIGH_TAU    = 0.0375           # label split for VIBE1\n",
    "RECALL_FLOOR     = 0.60             # recall floor for positives (high-VIBE)\n",
    "FEATURES_5       = ['GRAVY_VH','SAP_pos_Fv','GRAVY_HCDR3','SAP_pos_Hv','SAP_pos_Lv']\n",
    "FEATURES_38      = [\n",
    "    'SAP_pos_CDRH1','SAP_pos_CDRH2','SAP_pos_CDRH3','SAP_pos_CDRL1','SAP_pos_CDRL2','SAP_pos_CDRL3',\n",
    "    'SAP_pos_CDR','SAP_pos_Hv','SAP_pos_Lv','SAP_pos_Fv',\n",
    "    'SCM_neg_CDRH1','SCM_neg_CDRH2','SCM_neg_CDRH3','SCM_neg_CDRL1','SCM_neg_CDRL2','SCM_neg_CDRL3',\n",
    "    'SCM_neg_CDR','SCM_neg_Hv','SCM_neg_Lv','SCM_neg_Fv',\n",
    "    'SCM_pos_CDRH1','SCM_pos_CDRH2','SCM_pos_CDRH3','SCM_pos_CDRL1','SCM_pos_CDRL2','SCM_pos_CDRL3',\n",
    "    'SCM_pos_CDR','SCM_pos_Hv','SCM_pos_Lv','SCM_pos_Fv',\n",
    "    'GRAVY_VH','GRAVY_VL','GRAVY_HCDR1','GRAVY_HCDR2','GRAVY_HCDR3',\n",
    "    'GRAVY_LCDR1','GRAVY_LCDR2','GRAVY_LCDR3'\n",
    "]\n",
    "\n",
    "DATA_DESCR       = Path(\"final_all_descriptors.csv\")\n",
    "DEEPSP_IN        = Path(\"DeepSP_input.csv\")\n",
    "DEEPSP_OUT       = Path(\"DeepSP_descriptors.csv\")  \n",
    "DEEPPRED_SCRIPT  = Path(os.environ.get(\"DEEPSP_SCRIPT\", \"deepsp_predictor.py\"))\n",
    "OUTDIR           = Path(\"opt_outputs_desc\"); OUTDIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Mutagenesis limits \n",
    "MAX_HCDR3_POS = 6\n",
    "MAX_LCDR3_POS = 0           \n",
    "MUTS_PER_POS  = 2\n",
    "\n",
    "# Descriptor-only hydrophobicity score weights\n",
    "HYDRO_WEIGHT  = {'SAP_pos_Fv':1.0,'SAP_pos_Hv':1.0,'SAP_pos_Lv':1.0,'GRAVY_VH':0.5,'GRAVY_HCDR3':0.5}\n",
    "\n",
    "# helpers\n",
    "def ensure_cols(df: pd.DataFrame, cols: List[str]):\n",
    "    miss = [c for c in cols if c not in df.columns]\n",
    "    if miss: raise ValueError(f\"Missing columns: {miss}\")\n",
    "\n",
    "def kyte_doolittle(seq: str) -> float:\n",
    "    kd = {'I':4.5,'V':4.2,'L':3.8,'F':2.8,'C':2.5,'M':1.9,'A':1.8,'G':-0.4,'T':-0.7,\n",
    "          'S':-0.8,'W':-0.9,'Y':-1.3,'P':-1.6,'H':-3.2,'E':-3.5,'Q':-3.5,'D':-3.5,'N':-3.5,'K':-3.9,'R':-4.5}\n",
    "    vals = [kd.get(a,0) for a in seq]\n",
    "    return float(np.mean(vals)) if vals else 0.0\n",
    "\n",
    "def choose_threshold_with_recall_floor(y_true, proba, recall_floor=RECALL_FLOOR) -> float:\n",
    "    prec, rec, thr = precision_recall_curve(y_true, proba)\n",
    "    f1 = 2*(prec*rec)/np.maximum(prec+rec,1e-12)\n",
    "    mask = rec >= recall_floor\n",
    "    if mask.any():\n",
    "        k = np.argmax(f1[mask]); idx = np.arange(len(f1))[mask][k]\n",
    "        return float(thr[max(idx-1,0)] if idx>0 else 0.0)\n",
    "    idx = np.argmax(f1); return float(thr[max(idx-1,0)] if idx>0 else 0.0)\n",
    "\n",
    "def zscore_from_ref(s: pd.Series, ref_mean: float, ref_std: float) -> pd.Series:\n",
    "    sd = ref_std if ref_std != 0 else 1.0\n",
    "    return (s - ref_mean) / sd\n",
    "\n",
    "def creates_nglyc(seq: str) -> bool:\n",
    "    # scan for N-X-[S/T] (X != P)\n",
    "    for i in range(len(seq)-2):\n",
    "        if seq[i]=='N' and seq[i+1] != 'P' and seq[i+2] in ('S','T'):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# load base table \n",
    "print(\"Loading final_all_descriptors.csv ...\")\n",
    "df = pd.read_csv(DATA_DESCR)\n",
    "ensure_cols(df, ['Name','Status','VH','VL','VIBE1'] + FEATURES_38)\n",
    "\n",
    "# Reference z-stats on the 234 set\n",
    "z_means = df[FEATURES_38].mean()\n",
    "z_stds  = df[FEATURES_38].std(ddof=0).replace(0, 1.0)\n",
    "\n",
    "# train VIBE classifier on 5 features \n",
    "print(\"Training Elastic-Net VIBE classifier on 5 features ...\")\n",
    "df_v = df.dropna(subset=['VIBE1']).copy()\n",
    "df_v['y'] = (df_v['VIBE1'] > VIBE_HIGH_TAU).astype(int)\n",
    "\n",
    "X = df_v[FEATURES_5].values\n",
    "y = df_v['y'].values\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.20, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "vibe_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        penalty=\"elasticnet\", solver=\"saga\", l1_ratio=0.2,\n",
    "        C=0.1, class_weight=\"balanced\", max_iter=5000, random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "vibe_pipe.fit(X_tr, y_tr)\n",
    "proba_te = vibe_pipe.predict_proba(X_te)[:,1]\n",
    "thr_vibe = choose_threshold_with_recall_floor(y_te, proba_te, RECALL_FLOOR)\n",
    "print(f\"VIBE gate: ROC-AUC={roc_auc_score(y_te, proba_te):.3f} | AP={average_precision_score(y_te, proba_te):.3f} | thr={thr_vibe:.3f}\")\n",
    "\n",
    "#  generate single mutants (H/L CDR3)\n",
    "print(\"Generating single mutants in CDR3 (heavy & light) ...\")\n",
    "\n",
    "HYDROPHOBIC = set(\"VILFMYWA\")\n",
    "POSITIVE    = set(\"KRH\")\n",
    "SUBS_FOR = {\n",
    "    'V':['S','T'],'I':['S','T'],'L':['S','T'],'F':['S','N'],'M':['S','T'],'Y':['S','T'],'W':['S','N'],'A':['S','T'],\n",
    "    'K':['Q','E'],'R':['Q','E'],'H':['Q','N'],\n",
    "}\n",
    "\n",
    "parents = df[df['Status'].str.lower().eq('terminated')][['Name','VH','VL']].copy()\n",
    "mutants = []\n",
    "\n",
    "for _, r in parents.iterrows():\n",
    "    name, VH, VL = r['Name'], r['VH'], r['VL']\n",
    "    # crude HCDR3 window: C...W \n",
    "    c = VH.find('C'); w = VH.rfind('W')\n",
    "    if c != -1 and w != -1 and w > c:\n",
    "        H_idx = list(range(c, min(w+1, len(VH))))\n",
    "    else:\n",
    "        H_idx = list(range(len(VH)//2, len(VH)))  # fallback: second half of VH\n",
    "    # positions eligible for mutation\n",
    "    cand_idx = [i for i in H_idx if i < len(VH) and (VH[i] in HYDROPHOBIC or VH[i] in POSITIVE)]\n",
    "    cand_idx = cand_idx[:MAX_HCDR3_POS]\n",
    "\n",
    "    for i in cand_idx:\n",
    "        wt = VH[i]\n",
    "        for m in SUBS_FOR.get(wt, [])[:MUTS_PER_POS]:\n",
    "            if m == 'C': \n",
    "                continue\n",
    "            newVH = VH[:i] + m + VH[i+1:]\n",
    "            # avoid introducing NXS/T motif anywhere (conservative)\n",
    "            if creates_nglyc(newVH) or creates_nglyc(VL):\n",
    "                continue\n",
    "            mutants.append((f\"{name}|H{wt}{i+1}{m}\", name, newVH, VL, 'H', i+1, wt, m))\n",
    "\n",
    "# LCDR3 disabled \n",
    "\n",
    "mut_df = pd.DataFrame(mutants, columns=[\"MutantName\",\"Parent\",\"VH_mut\",\"VL_mut\",\"Chain\",\"Position\",\"WT\",\"Mut\"])\n",
    "print(f\"Mutants generated: {len(mut_df)} over {len(parents)} parents\")\n",
    "if mut_df.empty:\n",
    "    print(\"No mutants produced — consider relaxing limits.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# DeepSP recompute\n",
    "print(\"Preparing DeepSP input and invoking deepsp_predictor.py ...\")\n",
    "DEEPSP_IN.unlink(missing_ok=True)\n",
    "DEEPSP_OUT.unlink(missing_ok=True)\n",
    "\n",
    "inp = pd.DataFrame({\n",
    "    \"Name\": mut_df[\"MutantName\"],\n",
    "    \"Heavy_Chain\": mut_df[\"VH_mut\"],\n",
    "    \"Light_Chain\": mut_df[\"VL_mut\"],\n",
    "})\n",
    "inp.to_csv(DEEPSP_IN, index=False)\n",
    "\n",
    "# force predictor to run with the Python that has TF 2.20 + ANARCI \n",
    "DEEPSP_PYTHON = os.environ.get(\"DEEPSP_PYTHON\", sys.executable)\n",
    "print(\"DeepSP will run with:\", DEEPSP_PYTHON)\n",
    "env = os.environ.copy()\n",
    "env[\"PATH\"] = f\"{Path(DEEPSP_PYTHON).parent}:{env.get('PATH','')}\"\n",
    "env[\"TF_USE_LEGACY_KERAS\"] = \"1\"  \n",
    "\n",
    "if not DEEPPRED_SCRIPT.exists():\n",
    "    raise FileNotFoundError(f\"DeepSP predictor not found at: {DEEPPRED_SCRIPT.resolve()} \"\n",
    "                            f\"(set $DEEPSP_SCRIPT to override)\")\n",
    "\n",
    "res = subprocess.run([DEEPSP_PYTHON, str(DEEPPRED_SCRIPT)],\n",
    "                     capture_output=True, text=True, env=env)\n",
    "if res.returncode != 0:\n",
    "    print(\"=== DeepSP STDOUT ===\\n\", res.stdout)\n",
    "    print(\"=== DeepSP STDERR ===\\n\", res.stderr)\n",
    "    raise RuntimeError(\n",
    "        \"DeepSP predictor failed. Ensure this Python has TensorFlow 2.20 and ANARCI.\\n\"\n",
    "        \"Tips:\\n\"\n",
    "        \"  conda activate deepsp\\n\"\n",
    "        \"  pip uninstall -y keras  # avoid Keras-3 conflicts\\n\"\n",
    "        \"  export DEEPSP_PYTHON=$(python -c 'import sys; print(sys.executable)')\\n\"\n",
    "    )\n",
    "\n",
    "if not DEEPSP_OUT.exists():\n",
    "    raise FileNotFoundError(\"DeepSP_descriptors.csv was not produced by the predictor.\")\n",
    "\n",
    "# load DeepSP outputs & build feature table\n",
    "deep = pd.read_csv(DEEPSP_OUT)\n",
    "need = ['Name',\n",
    "    'SAP_pos_CDRH1','SAP_pos_CDRH2','SAP_pos_CDRH3','SAP_pos_CDRL1','SAP_pos_CDRL2','SAP_pos_CDRL3',\n",
    "    'SAP_pos_CDR','SAP_pos_Hv','SAP_pos_Lv','SAP_pos_Fv',\n",
    "    'SCM_neg_CDRH1','SCM_neg_CDRH2','SCM_neg_CDRH3','SCM_neg_CDRL1','SCM_neg_CDRL2','SCM_neg_CDRL3',\n",
    "    'SCM_neg_CDR','SCM_neg_Hv','SCM_neg_Lv','SCM_neg_Fv',\n",
    "    'SCM_pos_CDRH1','SCM_pos_CDRH2','SCM_pos_CDRH3','SCM_pos_CDRL1','SCM_pos_CDRL2','SCM_pos_CDRL3',\n",
    "    'SCM_pos_CDR','SCM_pos_Hv','SCM_pos_Lv','SCM_pos_Fv'\n",
    "]\n",
    "missing = [c for c in need if c not in deep.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"DeepSP_descriptors.csv missing columns: {missing}\")\n",
    "\n",
    "# Sanity - ensure the outputs correspond exactly to mutants \n",
    "deep_names = set(deep['Name'].tolist())\n",
    "mut_names  = set(mut_df['MutantName'].tolist())\n",
    "if deep_names != mut_names:\n",
    "    extra = deep_names - mut_names\n",
    "    missingN = mut_names - deep_names\n",
    "    raise ValueError(f\"DeepSP name mismatch.\\nExtra in DeepSP: {list(extra)[:5]}\\nMissing in DeepSP: {list(missingN)[:5]}\")\n",
    "\n",
    "# compute GRAVY and build 38 features\n",
    "name2vh = dict(zip(mut_df['MutantName'], mut_df['VH_mut']))\n",
    "name2vl = dict(zip(mut_df['MutantName'], mut_df['VL_mut']))\n",
    "\n",
    "gravy_rows = []\n",
    "for n in deep['Name']:\n",
    "    vh = name2vh[n]; vl = name2vl[n]\n",
    "    gravy_vh   = kyte_doolittle(vh)\n",
    "    gravy_hcdr3 = gravy_vh   \n",
    "    gravy_vl   = kyte_doolittle(vl)\n",
    "    gravy_rows.append((n, gravy_vh, gravy_hcdr3, gravy_vl))\n",
    "\n",
    "gravy_df = pd.DataFrame(gravy_rows, columns=['Name','GRAVY_VH','GRAVY_HCDR3','GRAVY_VL'])\n",
    "mut_desc = deep.merge(gravy_df, on='Name', how='left')\n",
    "\n",
    "# fill remaining GRAVY_* CDRs with 0.0 - column completeness\n",
    "for c in ['GRAVY_HCDR1','GRAVY_HCDR2','GRAVY_LCDR1','GRAVY_LCDR2','GRAVY_LCDR3']:\n",
    "    mut_desc[c] = 0.0\n",
    "\n",
    "# Build 5 features for VIBE gate\n",
    "ensure_cols(mut_desc, FEATURES_5)\n",
    "X_mut5 = mut_desc[FEATURES_5].values\n",
    "p_high = vibe_pipe.predict_proba(X_mut5)[:,1]\n",
    "mut_desc['VIBE_high_prob'] = p_high\n",
    "mut_desc['VIBE_pred'] = (p_high >= thr_vibe).astype(int)  # 1 = high (reject)\n",
    "\n",
    "# Attach meta \n",
    "mut_desc = mut_desc.merge(mut_df[['MutantName','Parent','Chain','Position','WT','Mut']],\n",
    "                          left_on='Name', right_on='MutantName', how='left')\n",
    "\n",
    "# rank by descriptor-only HydroScore \n",
    "survivors = mut_desc[mut_desc['VIBE_pred']==0].copy()\n",
    "if survivors.empty:\n",
    "    print(\"No mutants passed the VIBE gate. Consider raising the threshold or relaxing recall floor.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "# z-scores based on the 234-reference stats\n",
    "for k in HYDRO_WEIGHT.keys():\n",
    "    mu, sd = float(z_means[k]), float(z_stds[k])\n",
    "    survivors[f\"z_{k}\"] = zscore_from_ref(survivors[k], mu, sd)\n",
    "\n",
    "survivors[\"HydroScore38\"] = sum(HYDRO_WEIGHT[k] * survivors[f\"z_{k}\"] for k in HYDRO_WEIGHT.keys())\n",
    "\n",
    "# Final ranking: lowest VIBE prob, then lowest HydroScore38\n",
    "ranked = survivors.sort_values([\"VIBE_high_prob\",\"HydroScore38\"], ascending=[True, True]).copy()\n",
    "\n",
    "# Save\n",
    "OUTDIR.mkdir(exist_ok=True, parents=True)\n",
    "ranked_cols = ['Parent','Name','Chain','Position','WT','Mut','VIBE_high_prob','HydroScore38'] + list(HYDRO_WEIGHT.keys())\n",
    "ranked[ranked_cols].to_csv(OUTDIR/\"optimized_mutants_descriptor_only.csv\", index=False)\n",
    "\n",
    "print(f\"\\nOptimization complete.\")\n",
    "print(f\"Low-VIBE survivors ranked by HydroScore38 → {OUTDIR/'optimized_mutants_descriptor_only.csv'}\")\n",
    "print(f\"Gate: thr={thr_vibe:.3f} (recall floor {RECALL_FLOOR:.2f})  |  survivors: {len(survivors)} / {len(mut_desc)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa107fa",
   "metadata": {},
   "source": [
    "# H3 optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425e41e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading final_all_descriptors.csv ...\n",
      "Training Elastic-Net VIBE classifier on 5 features ...\n",
      "VIBE gate: ROC-AUC=0.678 | AP=0.345 | thr=0.456\n",
      "Generating single-site HCDR3 mutants ...\n",
      "Mutants generated: 1526 over 147 parents\n",
      "Preparing DeepSP input and invoking deepsp_predictor.py ...\n",
      "DeepSP will run with: /Users/tahuraazazattar/miniconda3/envs/deepsp_env/bin/python\n",
      "Survivors ranked by HydroScore38 → opt_outputs_H3/optimized_mutants_H3_ranked.csv\n",
      "Full mutant table → opt_outputs_H3/optimized_mutants_H3_full.csv\n",
      "Gate: thr=0.456 (recall floor 0.60)  |  survivors: 983 / 1526\n",
      "Done. Outputs in: /Users/tahuraazazattar/Library/CloudStorage/OneDrive-UniversityofBirmingham/Project/DeepSP/opt_outputs_H3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import os, sys, warnings, subprocess, re\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_curve, roc_auc_score, average_precision_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE     = 42\n",
    "VIBE_HIGH_TAU    = 0.0375           # label split for VIBE1  (1 = High-VIBE if VIBE1 > τ)\n",
    "RECALL_FLOOR     = 0.60             # recall floor for positives (high-VIBE)\n",
    "FEATURES_5       = ['GRAVY_VH','SAP_pos_Fv','GRAVY_HCDR3','SAP_pos_Hv','SAP_pos_Lv']\n",
    "FEATURES_38      = [\n",
    "    'SAP_pos_CDRH1','SAP_pos_CDRH2','SAP_pos_CDRH3','SAP_pos_CDRL1','SAP_pos_CDRL2','SAP_pos_CDRL3',\n",
    "    'SAP_pos_CDR','SAP_pos_Hv','SAP_pos_Lv','SAP_pos_Fv',\n",
    "    'SCM_neg_CDRH1','SCM_neg_CDRH2','SCM_neg_CDRH3','SCM_neg_CDRL1','SCM_neg_CDRL2','SCM_neg_CDRL3',\n",
    "    'SCM_neg_CDR','SCM_neg_Hv','SCM_neg_Lv','SCM_neg_Fv',\n",
    "    'SCM_pos_CDRH1','SCM_pos_CDRH2','SCM_pos_CDRH3','SCM_pos_CDRL1','SCM_pos_CDRL2','SCM_pos_CDRL3',\n",
    "    'SCM_pos_CDR','SCM_pos_Hv','SCM_pos_Lv','SCM_pos_Fv',\n",
    "    'GRAVY_VH','GRAVY_VL','GRAVY_HCDR1','GRAVY_HCDR2','GRAVY_HCDR3',\n",
    "    'GRAVY_LCDR1','GRAVY_LCDR2','GRAVY_LCDR3'\n",
    "]\n",
    "\n",
    "DATA_DESCR       = Path(\"final_all_descriptors.csv\")\n",
    "DEEPSP_IN        = Path(\"DeepSP_input.csv\")\n",
    "DEEPSP_OUT       = Path(\"DeepSP_descriptors.csv\")   # overwritten each run\n",
    "DEEPPRED_SCRIPT  = Path(os.environ.get(\"DEEPSP_SCRIPT\", \"deepsp_predictor.py\"))\n",
    "\n",
    "OUTDIR           = Path(\"opt_outputs_H3\"); OUTDIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Mutagenesis limits \n",
    "MAX_HCDR3_POS = 6        # maximum positions in H3 to mutate per parent\n",
    "MUTS_PER_POS  = 2        # maximum substitutions per chosen position\n",
    "\n",
    "# Descriptor-only hydrophobicity score weights\n",
    "HYDRO_WEIGHT  = {'SAP_pos_Fv':1.0,'SAP_pos_Hv':1.0,'SAP_pos_Lv':1.0,'GRAVY_VH':0.5,'GRAVY_HCDR3':0.5}\n",
    "\n",
    "FAIL_STRICT = {\"terminated\",\"withdrawn\",\"nfd\",\"no further development\"}\n",
    "\n",
    "#  helpers\n",
    "def ensure_cols(df: pd.DataFrame, cols: List[str]):\n",
    "    miss = [c for c in cols if c not in df.columns]\n",
    "    if miss: raise ValueError(f\"Missing columns: {miss}\")\n",
    "\n",
    "def kyte_doolittle(seq: str) -> float:\n",
    "    kd = {'I':4.5,'V':4.2,'L':3.8,'F':2.8,'C':2.5,'M':1.9,'A':1.8,'G':-0.4,'T':-0.7,\n",
    "          'S':-0.8,'W':-0.9,'Y':-1.3,'P':-1.6,'H':-3.2,'E':-3.5,'Q':-3.5,'D':-3.5,'N':-3.5,'K':-3.9,'R':-4.5}\n",
    "    vals = [kd.get(a,0) for a in seq]\n",
    "    return float(np.mean(vals)) if vals else 0.0\n",
    "\n",
    "def choose_threshold_with_recall_floor(y_true, proba, recall_floor=RECALL_FLOOR) -> float:\n",
    "    prec, rec, thr = precision_recall_curve(y_true, proba)\n",
    "    f1 = 2*(prec*rec)/np.maximum(prec+rec,1e-12)\n",
    "    mask = rec >= recall_floor\n",
    "    if mask.any():\n",
    "        k = np.argmax(f1[mask]); idx = np.arange(len(f1))[mask][k]\n",
    "        return float(thr[max(idx-1,0)] if idx>0 else 0.0)\n",
    "    idx = np.argmax(f1); return float(thr[max(idx-1,0)] if idx>0 else 0.0)\n",
    "\n",
    "def zscore_from_ref(s: pd.Series, ref_mean: float, ref_std: float) -> pd.Series:\n",
    "    sd = ref_std if ref_std != 0 else 1.0\n",
    "    return (s - ref_mean) / sd\n",
    "\n",
    "def creates_nglyc(seq: str) -> bool:\n",
    "    # conservative: scan whole sequence for N-X-[S/T] (X != P)\n",
    "    for i in range(len(seq)-2):\n",
    "        if seq[i]=='N' and seq[i+1] != 'P' and seq[i+2] in ('S','T'):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# H3 window: last C after FR3 (~80) to just before JH anchor WGQG/WGxG/FGxG/HGxG\n",
    "def find_h3_window(vh: str) -> Tuple[int,int] | None:\n",
    "    if not isinstance(vh, str) or len(vh) < 95: return None\n",
    "    c_after80 = [m.start() for m in re.finditer('C', vh[80:])]\n",
    "    if not c_after80: return None\n",
    "    start = 80 + c_after80[-1]\n",
    "    m = re.search(r'(W[AG]QG|WG.G|FG.G|HG.G)', vh[start:])\n",
    "    if not m: return None\n",
    "    stop = start + m.start()      # stop BEFORE anchor\n",
    "    s, e = start+1, stop\n",
    "    if e - s < 3: return None\n",
    "    return (s, e)\n",
    "\n",
    "#  load base table \n",
    "print(\"Loading final_all_descriptors.csv ...\")\n",
    "df = pd.read_csv(DATA_DESCR)\n",
    "ensure_cols(df, ['Name','Status','VH','VL','VIBE1'] + FEATURES_38)\n",
    "\n",
    "# Reference z-stats on the 234 set (for HydroScore scaling)\n",
    "z_means = df[FEATURES_38].mean()\n",
    "z_stds  = df[FEATURES_38].std(ddof=0).replace(0, 1.0)\n",
    "\n",
    "#  train VIBE classifier on 5 features\n",
    "print(\"Training Elastic-Net VIBE classifier on 5 features ...\")\n",
    "df_v = df.dropna(subset=['VIBE1']).copy()\n",
    "df_v['y'] = (df_v['VIBE1'] > VIBE_HIGH_TAU).astype(int)       # 1 = High-VIBE\n",
    "\n",
    "X = df_v[FEATURES_5].values\n",
    "y = df_v['y'].values\n",
    "\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.20, random_state=RANDOM_STATE, stratify=y)\n",
    "\n",
    "vibe_pipe = Pipeline([\n",
    "    (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        penalty=\"elasticnet\", solver=\"saga\", l1_ratio=0.2,\n",
    "        C=0.1, class_weight=\"balanced\", max_iter=5000, random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "vibe_pipe.fit(X_tr, y_tr)\n",
    "proba_te = vibe_pipe.predict_proba(X_te)[:,1]\n",
    "thr_vibe = choose_threshold_with_recall_floor(y_te, proba_te, RECALL_FLOOR)\n",
    "print(f\"VIBE gate: ROC-AUC={roc_auc_score(y_te, proba_te):.3f} | AP={average_precision_score(y_te, proba_te):.3f} | thr={thr_vibe:.3f}\")\n",
    "\n",
    "# generate single-site H3 mutants (heavy only)\n",
    "print(\"Generating single-site HCDR3 mutants ...\")\n",
    "\n",
    "HYDROPHOBIC = set(\"VILFMYWA\")\n",
    "POSITIVE    = set(\"KRH\")\n",
    "SUBS_FOR = {\n",
    "    'V':['S','T'],'I':['S','T'],'L':['S','T'],'F':['Y','S'],'M':['S','T'],'Y':['S','T'],'W':['Y','S'],'A':['S','T'],\n",
    "    'K':['Q','E'],'R':['Q','E'],'H':['Q','N'],\n",
    "}\n",
    "\n",
    "parents = df[df['Status'].str.lower().isin(FAIL_STRICT)][['Name','VH','VL']].copy()\n",
    "mutants = []\n",
    "\n",
    "for _, r in parents.iterrows():\n",
    "    name, VH, VL = r['Name'], r['VH'], r['VL']\n",
    "    win = find_h3_window(VH)\n",
    "    if not win: \n",
    "        continue\n",
    "    s, e = win\n",
    "    # candidate indices in H3 region (hydrophobic or + charged)\n",
    "    cand_idx = [i for i in range(s, e) if VH[i] in HYDROPHOBIC or VH[i] in POSITIVE]\n",
    "    cand_idx = cand_idx[:MAX_HCDR3_POS] if MAX_HCDR3_POS>0 else cand_idx\n",
    "\n",
    "    for i in cand_idx:\n",
    "        wt = VH[i]\n",
    "        for m in SUBS_FOR.get(wt, [])[:MUTS_PER_POS]:\n",
    "            if m == 'C': \n",
    "                continue\n",
    "            newVH = VH[:i] + m + VH[i+1:]\n",
    "            if creates_nglyc(newVH) or creates_nglyc(VL):\n",
    "                continue\n",
    "            mutants.append((f\"{name}|H{i+1}{wt}{m}\", name, newVH, VL, 'H', i+1, wt, m))\n",
    "\n",
    "mut_df = pd.DataFrame(mutants, columns=[\"MutantName\",\"Parent\",\"VH_mut\",\"VL_mut\",\"Chain\",\"Position\",\"WT\",\"Mut\"])\n",
    "print(f\"Mutants generated: {len(mut_df)} over {len(parents)} parents\")\n",
    "if mut_df.empty:\n",
    "    print(\"No mutants produced — consider relaxing limits.\")\n",
    "    sys.exit(0)\n",
    "\n",
    "#  DeepSP: recompute for PARENTS + MUTANTS \n",
    "print(\"Preparing DeepSP input and invoking deepsp_predictor.py ...\")\n",
    "DEEPSP_IN.unlink(missing_ok=True)\n",
    "DEEPSP_OUT.unlink(missing_ok=True)\n",
    "\n",
    "inp_mut = pd.DataFrame({\"Name\": mut_df[\"MutantName\"], \"Heavy_Chain\": mut_df[\"VH_mut\"], \"Light_Chain\": mut_df[\"VL_mut\"]})\n",
    "inp_par = parents.rename(columns={\"Name\":\"Name\",\"VH\":\"Heavy_Chain\",\"VL\":\"Light_Chain\"})[[\"Name\",\"Heavy_Chain\",\"Light_Chain\"]]\n",
    "inp = pd.concat([inp_par, inp_mut], ignore_index=True).drop_duplicates(subset=[\"Name\"])\n",
    "inp.to_csv(DEEPSP_IN, index=False)\n",
    "\n",
    "# force predictor to run with the Python that has TF 2.20 + ANARCI \n",
    "DEEPSP_PYTHON = os.environ.get(\"DEEPSP_PYTHON\", sys.executable)\n",
    "print(\"DeepSP will run with:\", DEEPSP_PYTHON)\n",
    "env = os.environ.copy()\n",
    "env[\"PATH\"] = f\"{Path(DEEPSP_PYTHON).parent}:{env.get('PATH','')}\"\n",
    "env[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
    "\n",
    "if not DEEPPRED_SCRIPT.exists():\n",
    "    raise FileNotFoundError(f\"DeepSP predictor not found at: {DEEPPRED_SCRIPT.resolve()} \"\n",
    "                            f\"(set $DEEPSP_SCRIPT to override)\")\n",
    "\n",
    "res = subprocess.run([DEEPSP_PYTHON, str(DEEPPRED_SCRIPT)],\n",
    "                     capture_output=True, text=True, env=env)\n",
    "if res.returncode != 0:\n",
    "    print(\"=== DeepSP STDOUT ===\\n\", res.stdout)\n",
    "    print(\"=== DeepSP STDERR ===\\n\", res.stderr)\n",
    "    raise RuntimeError(\"DeepSP predictor failed. Ensure TF2.20 + ANARCI are available.\")\n",
    "\n",
    "if not DEEPSP_OUT.exists():\n",
    "    raise FileNotFoundError(\"DeepSP_descriptors.csv was not produced by the predictor.\")\n",
    "\n",
    "# load DeepSP outputs & assemble features\n",
    "deep = pd.read_csv(DEEPSP_OUT)\n",
    "need = ['Name',\n",
    "    'SAP_pos_CDRH1','SAP_pos_CDRH2','SAP_pos_CDRH3','SAP_pos_CDRL1','SAP_pos_CDRL2','SAP_pos_CDRL3',\n",
    "    'SAP_pos_CDR','SAP_pos_Hv','SAP_pos_Lv','SAP_pos_Fv',\n",
    "    'SCM_neg_CDRH1','SCM_neg_CDRH2','SCM_neg_CDRH3','SCM_neg_CDRL1','SCM_neg_CDRL2','SCM_neg_CDRL3',\n",
    "    'SCM_neg_CDR','SCM_neg_Hv','SCM_neg_Lv','SCM_neg_Fv',\n",
    "    'SCM_pos_CDRH1','SCM_pos_CDRH2','SCM_pos_CDRH3','SCM_pos_CDRL1','SCM_pos_CDRL2','SCM_pos_CDRL3',\n",
    "    'SCM_pos_CDR','SCM_pos_Hv','SCM_pos_Lv','SCM_pos_Fv'\n",
    "]\n",
    "missing = [c for c in need if c not in deep.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"DeepSP_descriptors.csv missing columns: {missing}\")\n",
    "\n",
    "# SAP calibration: map DeepSP SAPs to original scale using parents \n",
    "parents_orig = df[['Name','SAP_pos_Fv','SAP_pos_Hv','SAP_pos_Lv']].dropna()\n",
    "deep_par     = deep[['Name','SAP_pos_Fv','SAP_pos_Hv','SAP_pos_Lv']].dropna()\n",
    "cal = parents_orig.merge(deep_par, on=\"Name\", suffixes=(\"_orig\",\"_deep\"))\n",
    "\n",
    "def fit_map(deep_vals, orig_vals):\n",
    "    x = np.asarray(deep_vals, float)\n",
    "    y = np.asarray(orig_vals, float)\n",
    "    a, b = np.polyfit(x, y, 1)\n",
    "    return float(a), float(b)\n",
    "\n",
    "maps = {}\n",
    "for key in [\"SAP_pos_Fv\",\"SAP_pos_Hv\",\"SAP_pos_Lv\"]:\n",
    "    a,b = fit_map(cal[f\"{key}_deep\"], cal[f\"{key}_orig\"])\n",
    "    maps[key] = (a,b)\n",
    "\n",
    "def apply_calibration(df_in):\n",
    "    out = df_in.copy()\n",
    "    for key,(a,b) in maps.items():\n",
    "        out[key] = a*out[key].astype(float) + b\n",
    "    return out\n",
    "\n",
    "deep_cal = apply_calibration(deep)\n",
    "\n",
    "# build mutant feature table \n",
    "name2vh = dict(zip(mut_df['MutantName'], mut_df['VH_mut']))\n",
    "name2vl = dict(zip(mut_df['MutantName'], mut_df['VL_mut']))\n",
    "\n",
    "# GRAVY on VH and HCDR3 (heuristic window), plus GRAVY_VL \n",
    "gravy_rows = []\n",
    "for n in mut_df['MutantName']:\n",
    "    vh = name2vh[n]; vl = name2vl[n]\n",
    "    gravy_vh   = kyte_doolittle(vh)\n",
    "    # H3-only average using same window function\n",
    "    win = find_h3_window(vh)\n",
    "    if win:\n",
    "        s,e = win; gravy_hcdr3 = kyte_doolittle(vh[s:e])\n",
    "    else:\n",
    "        gravy_hcdr3 = gravy_vh  # fallback\n",
    "    gravy_vl   = kyte_doolittle(vl)\n",
    "    gravy_rows.append((n, gravy_vh, gravy_hcdr3, gravy_vl))\n",
    "gravy_df = pd.DataFrame(gravy_rows, columns=['Name','GRAVY_VH','GRAVY_HCDR3','GRAVY_VL'])\n",
    "\n",
    "mut_desc = deep_cal[deep_cal['Name'].isin(mut_df['MutantName'])].merge(gravy_df, on='Name', how='left')\n",
    "for c in ['GRAVY_HCDR1','GRAVY_HCDR2','GRAVY_LCDR1','GRAVY_LCDR2','GRAVY_LCDR3']:\n",
    "    mut_desc[c] = 0.0\n",
    "\n",
    "ensure_cols(mut_desc, FEATURES_5)\n",
    "\n",
    "# Attach meta \n",
    "mut_desc = mut_desc.merge(mut_df[['MutantName','Parent','Chain','Position','WT','Mut']],\n",
    "                          left_on='Name', right_on='MutantName', how='left')\n",
    "\n",
    "# Attach parent baselines for Δ computations\n",
    "parents_base = df[['Name','VIBE1','GRAVY_VH','GRAVY_HCDR3','SAP_pos_Fv','SAP_pos_Hv','SAP_pos_Lv','Status']].rename(\n",
    "    columns={'Name':'Parent','VIBE1':'VIBE1_parent',\n",
    "             'GRAVY_VH':'GRAVY_VH_parent','GRAVY_HCDR3':'GRAVY_HCDR3_parent',\n",
    "             'SAP_pos_Fv':'SAP_pos_Fv_parent','SAP_pos_Hv':'SAP_pos_Hv_parent','SAP_pos_Lv':'SAP_pos_Lv_parent'})\n",
    "mut_desc = mut_desc.merge(parents_base, on='Parent', how='left')\n",
    "\n",
    "# VIBE gate on 5 features \n",
    "X_mut5 = mut_desc[FEATURES_5].values\n",
    "p_high = vibe_pipe.predict_proba(X_mut5)[:,1]\n",
    "mut_desc['VIBE_high_prob'] = p_high\n",
    "mut_desc['VIBE_pred'] = (p_high >= thr_vibe).astype(int)  # 1 = high (reject)\n",
    "mut_desc['p_low'] = 1.0 - mut_desc['VIBE_high_prob']\n",
    "\n",
    "# Δ vs parent (after calibration) \n",
    "mut_desc['Delta_SAP_pos_Fv']  = mut_desc['SAP_pos_Fv']  - mut_desc['SAP_pos_Fv_parent']\n",
    "mut_desc['Delta_SAP_pos_Hv']  = mut_desc['SAP_pos_Hv']  - mut_desc['SAP_pos_Hv_parent']\n",
    "mut_desc['Delta_SAP_pos_Lv']  = mut_desc['SAP_pos_Lv']  - mut_desc['SAP_pos_Lv_parent']\n",
    "mut_desc['Delta_GRAVY_VH']    = mut_desc['GRAVY_VH']    - mut_desc['GRAVY_VH_parent']\n",
    "mut_desc['Delta_GRAVY_HCDR3'] = mut_desc['GRAVY_HCDR3'] - mut_desc['GRAVY_HCDR3_parent']\n",
    "\n",
    "# survivors and ranking \n",
    "survivors = mut_desc[mut_desc['VIBE_pred']==0].copy()   # pass gate (low risk)\n",
    "if survivors.empty:\n",
    "    print(\"No mutants passed the VIBE gate. Consider raising the threshold or relaxing recall floor.\")\n",
    "else:\n",
    "    # z-scores \n",
    "    for k in HYDRO_WEIGHT.keys():\n",
    "        mu, sd = float(z_means[k]), float(z_stds[k])\n",
    "        survivors[f\"z_{k}\"] = zscore_from_ref(survivors[k], mu, sd)\n",
    "    survivors[\"HydroScore38\"] = sum(HYDRO_WEIGHT[k] * survivors[f\"z_{k}\"] for k in HYDRO_WEIGHT.keys())\n",
    "\n",
    "    ranked = survivors.sort_values([\"VIBE_high_prob\",\"HydroScore38\"], ascending=[True, True]).copy()\n",
    "    ranked_cols = ['Parent','Name','Chain','Position','WT','Mut','VIBE_high_prob','p_low','HydroScore38'] + list(HYDRO_WEIGHT.keys()) + \\\n",
    "                  ['Delta_SAP_pos_Fv','Delta_GRAVY_HCDR3']\n",
    "    ranked[ranked_cols].to_csv(OUTDIR/\"optimized_mutants_H3_ranked.csv\", index=False)\n",
    "    print(f\"Survivors ranked by HydroScore38 → {OUTDIR/'optimized_mutants_H3_ranked.csv'}\")\n",
    "\n",
    "# Save full table\n",
    "mut_desc.to_csv(OUTDIR/\"optimized_mutants_H3_full.csv\", index=False)\n",
    "print(f\"Full mutant table → {OUTDIR/'optimized_mutants_H3_full.csv'}\")\n",
    "print(f\"Gate: thr={thr_vibe:.3f} (recall floor {RECALL_FLOOR:.2f})  |  survivors: {len(survivors)} / {len(mut_desc)}\")\n",
    "\n",
    "# PLOTS \n",
    "def savefig(path): \n",
    "    plt.tight_layout(); plt.savefig(path, dpi=220); plt.close()\n",
    "\n",
    "# (1) Multi-objective landscape (ΔSAP_pos_Fv vs p_low)\n",
    "plt.figure(figsize=(6.8,4.6))\n",
    "plt.scatter(mut_desc['Delta_SAP_pos_Fv'], mut_desc['p_low'], alpha=0.75, edgecolor=\"black\")\n",
    "plt.axvline(0, linestyle=\"--\", linewidth=1); plt.axhline(1.0-thr_vibe, linestyle=\"--\", linewidth=1)\n",
    "plt.xlabel(\"Δ SAP_pos_Fv (mutant − parent)  [smaller = better]\")\n",
    "plt.ylabel(\"P(Low-VIBE)  [bigger = better]\")\n",
    "plt.title(\"H3 optimisation — multi-objective landscape\")\n",
    "savefig(OUTDIR/\"opt_H3_landscape.png\")\n",
    "\n",
    "# (2) Pareto front (non-dominated)\n",
    "vals = mut_desc[['Delta_SAP_pos_Fv','p_low']].dropna().to_numpy()\n",
    "dominated = np.zeros(len(vals), dtype=bool)\n",
    "for i in range(len(vals)):\n",
    "    better = (vals[:,0] <= vals[i,0]) & (vals[:,1] >= vals[i,1])\n",
    "    strict = (vals[:,0] <  vals[i,0]) | (vals[:,1] >  vals[i,1])\n",
    "    if np.any(better & strict): dominated[i] = True\n",
    "pareto = mut_desc.loc[~dominated, ['Delta_SAP_pos_Fv','p_low']]\n",
    "\n",
    "plt.figure(figsize=(6.8,4.6))\n",
    "plt.scatter(mut_desc['Delta_SAP_pos_Fv'], mut_desc['p_low'], alpha=0.45, edgecolor=\"black\", label=\"Mutants\")\n",
    "plt.scatter(pareto['Delta_SAP_pos_Fv'], pareto['p_low'], s=80, marker=\"D\", edgecolor=\"black\", label=\"Pareto\")\n",
    "plt.axvline(0, linestyle=\"--\", linewidth=1); plt.axhline(1.0-thr_vibe, linestyle=\"--\", linewidth=1)\n",
    "plt.xlabel(\"Δ SAP_pos_Fv (smaller = better)\"); plt.ylabel(\"P(Low-VIBE) (bigger = better)\")\n",
    "plt.title(\"H3 optimisation — Pareto front\"); plt.legend()\n",
    "savefig(OUTDIR/\"opt_H3_pareto.png\")\n",
    "\n",
    "# (3) Funnel: total → pass gate → rescued (ΔSAP_pos_Fv<0)\n",
    "resc_mask = (mut_desc['VIBE_pred']==0) & (mut_desc['Delta_SAP_pos_Fv'] < 0)\n",
    "stages = [\"Mutants\",\"Pass gate\",\"Rescued\"]\n",
    "counts = [len(mut_desc), int((mut_desc['VIBE_pred']==0).sum()), int(resc_mask.sum())]\n",
    "plt.figure(figsize=(6.8,4.2))\n",
    "plt.plot(range(len(stages)), counts, marker=\"o\")\n",
    "for i,(s,c) in enumerate(zip(stages, counts)): plt.text(i, c, str(c), ha=\"center\", va=\"bottom\")\n",
    "plt.xticks(range(len(stages)), stages); plt.ylabel(\"Count\"); plt.title(\"H3 optimisation — funnel\")\n",
    "savefig(OUTDIR/\"opt_H3_funnel.png\")\n",
    "\n",
    "# (4) Top-15 rescued by ΔSAP_pos_Fv\n",
    "resc = mut_desc[resc_mask].copy().sort_values(\"Delta_SAP_pos_Fv\")\n",
    "top15 = resc.head(15)\n",
    "plt.figure(figsize=(8.2,4.8))\n",
    "if not top15.empty:\n",
    "    plt.barh(top15[\"Name\"], -top15[\"Delta_SAP_pos_Fv\"], edgecolor=\"black\")\n",
    "    plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"−Δ SAP_pos_Fv (bigger = more hydrophobicity reduction)\")\n",
    "plt.title(\"H3 optimisation — Top 15 rescued by ΔSAP_pos_Fv\")\n",
    "savefig(OUTDIR/\"opt_H3_top15_rescued.png\")\n",
    "\n",
    "# (5) Slope chart: parent → best passing mutant (top 12 parents)\n",
    "best = mut_desc[mut_desc['VIBE_pred']==0].copy()\n",
    "if not best.empty:\n",
    "    best = best.loc[best.groupby(\"Parent\")[\"Delta_SAP_pos_Fv\"].idxmin()].sort_values(\"Delta_SAP_pos_Fv\").head(12)\n",
    "    plt.figure(figsize=(8.2,4.8))\n",
    "    for _, row in best.iterrows():\n",
    "        plt.plot([0,1],[row[\"SAP_pos_Fv_parent\"], row[\"SAP_pos_Fv\"]], marker=\"o\")\n",
    "    plt.xticks([0,1], [\"Parent\",\"Best mutant (pass)\"]); plt.ylabel(\"SAP_pos_Fv\")\n",
    "    plt.title(\"H3 optimisation — parent → best mutant (top 12)\")\n",
    "    savefig(OUTDIR/\"opt_H3_slope_top12.png\")\n",
    "\n",
    "# (6) Δ-histograms (Pass vs Fail) for ΔGRAVY_HCDR3 and ΔSAP_pos_Fv\n",
    "for col in [\"Delta_GRAVY_HCDR3\",\"Delta_SAP_pos_Fv\"]:\n",
    "    a = mut_desc.loc[mut_desc[\"VIBE_pred\"]==0, col].dropna().values\n",
    "    b = mut_desc.loc[mut_desc[\"VIBE_pred\"]==1, col].dropna().values\n",
    "    bins = np.histogram(np.concatenate([a,b]) if (len(a)+len(b))>0 else [0], bins=24)[1]\n",
    "    plt.figure(figsize=(6.8,4.6))\n",
    "    plt.hist(a, bins=bins, alpha=0.7, edgecolor=\"black\", label=\"Pass\")\n",
    "    plt.hist(b, bins=bins, alpha=0.7, edgecolor=\"black\", label=\"Fail\")\n",
    "    plt.axvline(0, linestyle=\"--\", linewidth=1)\n",
    "    plt.xlabel(f\"{col}  (negative = improved)\"); plt.ylabel(\"Count\"); plt.legend()\n",
    "    plt.title(f\"H3 optimisation — {col} by gate\")\n",
    "    savefig(OUTDIR/f\"opt_H3_hist_{col}.png\")\n",
    "\n",
    "# (7) Substitution matrix (WT → Mut)\n",
    "subs = mut_desc.pivot_table(index=\"WT\", columns=\"Mut\", values=\"Name\", aggfunc=\"count\", fill_value=0)\n",
    "plt.figure(figsize=(7.8,6.0))\n",
    "plt.imshow(subs, aspect=\"auto\")\n",
    "plt.xticks(range(len(subs.columns)), subs.columns)\n",
    "plt.yticks(range(len(subs.index)), subs.index)\n",
    "plt.colorbar(label=\"Count\"); plt.title(\"H3 optimisation — amino-acid substitutions (WT → Mut)\")\n",
    "savefig(OUTDIR/\"opt_H3_substitution_matrix.png\")\n",
    "\n",
    "# (8) Positions targeted (H3)\n",
    "pos_counts = mut_desc[\"Position\"].value_counts().sort_index()\n",
    "plt.figure(figsize=(7.8,4.0))\n",
    "plt.bar(pos_counts.index.astype(str), pos_counts.values, edgecolor=\"black\")\n",
    "plt.xlabel(\"Heavy-chain position (HCDR3)\"); plt.ylabel(\"Count\")\n",
    "plt.title(\"H3 optimisation — positions targeted\")\n",
    "savefig(OUTDIR/\"opt_H3_positions.png\")\n",
    "\n",
    "# (9) Mini-radar gallery (4 parents): normalised per panel\n",
    "def radar_one(row, out_png):\n",
    "    feats = [\"SAP_pos_Fv\",\"SAP_pos_Hv\",\"SAP_pos_Lv\",\"GRAVY_VH\",\"GRAVY_HCDR3\"]\n",
    "    pv = [row[f\"{f}_parent\"] for f in feats]\n",
    "    mv = [row[f] for f in feats]\n",
    "    allvals = np.array(pv+mv, float)\n",
    "    mn, mx = np.nanmin(allvals), np.nanmax(allvals)\n",
    "    if mx-mn == 0: \n",
    "        return\n",
    "    pv = (np.array(pv)-mn)/(mx-mn); mv = (np.array(mv)-mn)/(mx-mn)\n",
    "    ang = np.linspace(0, 2*np.pi, len(feats), endpoint=False)\n",
    "    pv = np.concatenate([pv, pv[:1]]); mv = np.concatenate([mv, mv[:1]]); ang = np.concatenate([ang, ang[:1]])\n",
    "    fig = plt.figure(figsize=(4.6,4.6)); ax = fig.add_subplot(111, polar=True)\n",
    "    ax.plot(ang, pv); ax.fill(ang, pv, alpha=0.25)\n",
    "    ax.plot(ang, mv); ax.fill(ang, mv, alpha=0.25)\n",
    "    ax.set_xticks(ang[:-1]); ax.set_xticklabels(feats)\n",
    "    ax.set_title(f\"Biophysical profile: {row['Parent']}\", y=1.08)\n",
    "    fig.tight_layout(); fig.savefig(out_png, dpi=220); plt.close(fig)\n",
    "\n",
    "passing = mut_desc[mut_desc['VIBE_pred']==0]\n",
    "if not passing.empty:\n",
    "    top4 = (passing.groupby(\"Parent\")[\"Delta_SAP_pos_Fv\"].min().sort_values().head(4)).index.tolist()\n",
    "    for i,pn in enumerate(top4, 1):\n",
    "        row = passing[passing[\"Parent\"]==pn].sort_values(\"Delta_SAP_pos_Fv\").iloc[0]\n",
    "        radar_one(row, OUTDIR/f\"opt_H3_radar_{i}.png\")\n",
    "\n",
    "print(\"Done. Outputs in:\", OUTDIR.resolve())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepsp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
